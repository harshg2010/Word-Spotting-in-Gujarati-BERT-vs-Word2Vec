{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Word Spotting using Word2Vec Model"
      ],
      "metadata": {
        "id": "UV67RfZiYoiI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyioRHMdJ23U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izBXfiHeJ6bg"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/filtered_data.csv',encoding = \"utf-8\")\n",
        "df.head()\n",
        "data=df.iloc[0:200,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOra4Qg8or4F",
        "outputId": "e7c931e4-2245-4de5-a9dc-19590b9cefa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  text target_word\n",
            "0    1 એપ્રિલ 2007ના દિવસે નોકિયાના નેટવર્ક્સ બિઝને...        સાથે\n",
            "1    મહાવીર સ્વામી, છેલ્લા તિર્થંકર, ક્ષત્રિય કુળમા...     વર્ણનાં\n",
            "2    બુદ્ધિપ્રકાશ ‍ ગુજરાતી ભાષાનું ગુજરાત વિદ્યા સ...     ગુજરાતી\n",
            "3                             ગુજરાત અને ભારતમાં સ્થાન         અને\n",
            "4                             ગુજરાત અને ભારતમાં સ્થાન       સ્થાન\n",
            "..                                                 ...         ...\n",
            "195  રાણા રણમલ પછી સને ૧૫૦૯ના વર્ષમાં રાણા સાંગા મે...     હુમલાથી\n",
            "196  સંજય ગાંધી રાષ્ટ્રીય ઉદ્યાન, જે પહેલા બોરિવલી ...      જાણીતો\n",
            "197  વિક્ટોરિયા દ્વીપ તેના પરિશિષ્ટ સાથે લાગોસ દ્વી...         બીચ\n",
            "198  ઉમરવીડી એ ભારત દેશના પશ્ચિમ ભાગમાં આવેલા ગુજરા...           જ\n",
            "199  ડુંગરાપુરા ભારત દેશના પશ્ચિમ ભાગમાં આવેલા ગુજર...           જ\n",
            "\n",
            "[200 rows x 2 columns]\n",
            "(200, 2)\n"
          ]
        }
      ],
      "source": [
        "print(data)\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUP61NtRpQy9",
        "outputId": "3315e3d5-53ca-40e6-8cb5-ef63fbeeb055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 7.196515371504324\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Sample dataset\n",
        "# training_data = [\n",
        "#     \"એપ્રિલ 2007ના દિવસે નોકિયાના નેટવર્ક્સ બિઝનેસ ગ્રૂપનેસિમેન્સ ના કેરિયર સાથે સંકળાયેલા સંચાલન અને\"\n",
        "# ]\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_data = [sentence.lower().split() for sentence in training_data]\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences=tokenized_data, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Function to spot words using Word2Vec embeddings\n",
        "def spot_words(text, model, threshold=0.5):\n",
        "    words = text.lower().split()  # Tokenize text\n",
        "    spotted_words = []\n",
        "    for word in words:\n",
        "        if word in model.wv.key_to_index:  # Check if word is in vocabulary\n",
        "            word_vector = model.wv[word].reshape(1, -1)\n",
        "            # Calculate cosine similarity with other words in the dataset\n",
        "            similarities = {\n",
        "                target_word: cosine_similarity(word_vector, model.wv[target_word].reshape(1, -1))\n",
        "                for target_word in model.wv.index_to_key\n",
        "            }\n",
        "            # Filter similar words based on threshold\n",
        "            similar_words = [target_word for target_word, similarity in similarities.items() if similarity > threshold]\n",
        "            spotted_words.extend(similar_words)\n",
        "    return spotted_words\n",
        "\n",
        "def calculate_accuracy_from_dataframe(model, dataframe, text_column, similar_words_column, threshold=0.5):\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for index, row in dataframe.iterrows():\n",
        "        text = row[text_column]\n",
        "        correct_similar_words = row[similar_words_column]\n",
        "\n",
        "        spotted_words = spot_words(text, model, threshold)\n",
        "\n",
        "        for word in spotted_words:\n",
        "            if word in correct_similar_words:\n",
        "                correct_predictions += 1\n",
        "            total_predictions += 1\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    return accuracy * 100  # Convert to percentage\n",
        "\n",
        "\n",
        "# Example usage\n",
        "text = \"\"\n",
        "spotted_words = spot_words(text, model)\n",
        "print(\"Spotted words:\", spotted_words)\n",
        "\n",
        "# accuracy = calculate_accuracy_from_dataframe(model, data, 'text', 'target_word')\n",
        "# print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89E-hqiccKat"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"your_dataset.csv\")  # Assuming your dataset is in CSV format\n",
        "\n",
        "# Assuming your dataset has a column named 'text' containing the sentences\n",
        "# Tokenize the dataset\n",
        "tokenized_data = [sentence.lower().split() for sentence in data['text']]\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences=tokenized_data, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Optionally, you can save the trained model\n",
        "model.save(\"trained_word2vec_model.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmOAyB8K7Knp",
        "outputId": "e5207e2e-770a-4507-b279-9a5ea1ceefa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 7.196515371504324\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_data = [sentence.lower().split() for sentence in training_data]\n",
        "\n",
        "# Train Word2Vec model for 10 epochs\n",
        "model = Word2Vec(sentences=tokenized_data, vector_size=100, window=5, min_count=1, workers=4, epochs=10)\n",
        "\n",
        "# Function to spot words using Word2Vec embeddings\n",
        "def spot_words(text, model, threshold=0.5):\n",
        "    words = text.lower().split()  # Tokenize text\n",
        "    spotted_words = []\n",
        "    for word in words:\n",
        "        if word in model.wv.key_to_index:  # Check if word is in vocabulary\n",
        "            word_vector = model.wv[word].reshape(1, -1)\n",
        "            # Calculate cosine similarity with other words in the dataset\n",
        "            similarities = {\n",
        "                target_word: cosine_similarity(word_vector, model.wv[target_word].reshape(1, -1))\n",
        "                for target_word in model.wv.index_to_key\n",
        "            }\n",
        "            # Filter similar words based on threshold\n",
        "            similar_words = [target_word for target_word, similarity in similarities.items() if similarity > threshold]\n",
        "            spotted_words.extend(similar_words)\n",
        "    return spotted_words\n",
        "\n",
        "def calculate_accuracy_from_dataframe(model, dataframe, text_column, similar_words_column, threshold=0.5):\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for index, row in dataframe.iterrows():\n",
        "        text = row[text_column]\n",
        "        correct_similar_words = row[similar_words_column]\n",
        "\n",
        "        spotted_words = spot_words(text, model, threshold)\n",
        "\n",
        "        for word in spotted_words:\n",
        "            if word in correct_similar_words:\n",
        "                correct_predictions += 1\n",
        "            total_predictions += 1\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    return accuracy * 100\n",
        "\n",
        "\n",
        "accuracy = calculate_accuracy_from_dataframe(model, data, 'text', 'target_word')\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnNCTLpyOl6A",
        "outputId": "d75424a7-1a05-4736-97c7-bac30efbefde"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "# data = pd.DataFrame({\n",
        "#     'text': [\"sentence one\", \"sentence two\", \"sentence three\"],\n",
        "#     'training_data': [[\"word1\", \"word2\"], [\"word3\", \"word4\"], [\"word5\", \"word6\"]]\n",
        "# })\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_data = [sentence.lower().split() for sentence in data['text']]\n",
        "\n",
        "# Train Word2Vec model for 10 epochs\n",
        "model = Word2Vec(sentences=tokenized_data, vector_size=100, window=5, min_count=1, workers=4, epochs=10)\n",
        "\n",
        "# Function to spot words using Word2Vec embeddings\n",
        "def spot_words(text, model, threshold=0.5):\n",
        "    words = text.lower().split()  # Tokenize text\n",
        "    spotted_words = []\n",
        "    for word in words:\n",
        "        if word in model.wv.key_to_index:  # Check if word is in vocabulary\n",
        "            word_vector = model.wv[word].reshape(1, -1)\n",
        "            # Calculate cosine similarity with other words in the dataset\n",
        "            similarities = {\n",
        "                target_word: cosine_similarity(word_vector, model.wv[target_word].reshape(1, -1))\n",
        "                for target_word in model.wv.index_to_key\n",
        "            }\n",
        "            # Filter similar words based on threshold\n",
        "            similar_words = [target_word for target_word, similarity in similarities.items() if similarity > threshold]\n",
        "            spotted_words.extend(similar_words)\n",
        "    return spotted_words\n",
        "\n",
        "def calculate_accuracy_from_dataframe(model, dataframe, text_column, similar_words_column, threshold=0.5):\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for index, row in dataframe.iterrows():\n",
        "        text = row[text_column]\n",
        "        correct_similar_words = row[similar_words_column]\n",
        "\n",
        "        spotted_words = spot_words(text, model, threshold)\n",
        "\n",
        "        for word in spotted_words:\n",
        "            if word in correct_similar_words:\n",
        "                correct_predictions += 1\n",
        "            total_predictions += 1\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    return accuracy * 100\n",
        "\n",
        "# Function to train the model and calculate accuracy after each epoch\n",
        "def train_model_with_accuracy(model, tokenized_data, data, text_column, similar_words_column, threshold=0.5):\n",
        "    for epoch in range(1, 11):  # 10 epochs\n",
        "        model.train(tokenized_data, total_examples=len(tokenized_data), epochs=1)  # Train for one epoch\n",
        "        accuracy = calculate_accuracy_from_dataframe(model, data, text_column, similar_words_column, threshold)\n",
        "        print(f\"Epoch {epoch} - Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Example usage\n",
        "train_model_with_accuracy(model, tokenized_data, data, 'text', 'target_word')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Sample dataset\n",
        "training_data = [\n",
        "    \"સ્વતંત્રતા સંગ્રામની ભાષા અને રાજ્યની ભાષા સાથે બંનેનું કામ કર્યું. ભાષા એ એક સાંસ્કૃતિક મૂળ છે જે માણસને અનેક અનેક અનુભવો આપે છે.\"\n",
        "]\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_data = [sentence.lower().split() for sentence in training_data]\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences=tokenized_data, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "def spot_words(text, word_to_spot, model, threshold=0.5):\n",
        "    words = text.lower().split()  # Tokenize text\n",
        "    similarity_scores = {}\n",
        "    if word_to_spot in model.wv.key_to_index:  # Check if word is in vocabulary\n",
        "        word_vector = model.wv[word_to_spot].reshape(1, -1)\n",
        "        # Calculate cosine similarity with other words in the dataset\n",
        "        for word in words:\n",
        "            if word in model.wv.key_to_index:\n",
        "                similarity = cosine_similarity(word_vector, model.wv[word].reshape(1, -1))\n",
        "                similarity_scores[word] = similarity[0][0]\n",
        "    return similarity_scores\n",
        "\n",
        "text = \"સ્વતંત્રતા સંગ્રામની ભાષા અને રાજ્યની ભાષા સાથે બંનેનું કામ કર્યું. ભાષા એ એક સાંસ્કૃતિક મૂળ છે જે માણસને અનેક અનેક અનુભવો આપે છે.\"\n",
        "\n",
        "word_to_spot = \"સ્વતંત્રતા\"\n",
        "similarity_scores = spot_words(text, word_to_spot, model)\n",
        "print(\"Similarity scores for word\\n\", word_to_spot, \":\", similarity_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6aGnCUW78Eo",
        "outputId": "3381a3ff-3baf-44af-a7db-e9057bc4a714"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity scores for word\n",
            " સ્વતંત્રતા : {'સ્વતંત્રતા': 1.0, 'સંગ્રામની': -0.27683428, 'ભાષા': 0.0023639845, 'અને': -0.1268385, 'રાજ્યની': 0.110694304, 'સાથે': 0.31900457, 'બંનેનું': 0.09679906, 'કામ': -0.038063146, 'કર્યું.': -0.0016928422, 'એ': 0.08638984, 'એક': -0.0019156924, 'સાંસ્કૃતિક': -0.049855027, 'મૂળ': 0.16214159, 'છે': 0.00064623356, 'જે': -0.0386624, 'માણસને': -0.046653334, 'અનેક': -0.1598332, 'અનુભવો': 0.00053698407, 'આપે': 0.097350374, 'છે.': -0.0350891}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}