{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyFUarHaJGpK",
        "outputId": "2859d3eb-3f42-45cd-9b2d-b744d750dcc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Default model"
      ],
      "metadata": {
        "id": "rkSeqm1mFBOR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYgrX52Beil9",
        "outputId": "39101e74-e932-4425-8d01-2ac2040375f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top spotted words similar to 'ગુજરાતી' in the document:\n",
            "- ગુજરાતી (Similarity Score: 1.0000)\n",
            "- ગુજરાતી (Similarity Score: 1.0000)\n",
            "- કર્યું (Similarity Score: 0.8517)\n",
            "- સાથે (Similarity Score: 0.8458)\n",
            "- તેમને (Similarity Score: 0.8453)\n",
            "- છે (Similarity Score: 0.8394)\n",
            "- છે (Similarity Score: 0.8394)\n",
            "- છે (Similarity Score: 0.8394)\n",
            "- છે (Similarity Score: 0.8394)\n",
            "- ##નું (Similarity Score: 0.8373)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, BertForMaskedLM\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Load the trained model\n",
        "model_name = \"l3cube-pune/gujarati-bert\"\n",
        "model = BertForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Input Gujarati text document\n",
        "gujarati_text = \"સ્વતંત્રતા સંગ્રામની ભાષા અને રાજ્યની ભાષા સાથે બંનેનું કામ કર્યું. ભાષા એ એક સાંસ્કૃતિક મૂળ છે જે માણસને અનેક અનેક અનુભવો આપે છે.ગુજરાતી ભાષા તેમને આત્મતૃપ્તિની અનુભૂતિ આપે છે જે અન્ય ભાષાઓ નહીં આપે. મહાત્મા ગાંધીએ ગુજરાતી ભાષાને ગૌરવ અને આત્માનંદનું પ્રતિષ્ઠાન આપ્યું. ભાષા સામાજિક સંસ્કૃતિનું એક મહત્વપૂર્ણ અંગ છે.\"\n",
        "\n",
        "\n",
        "# Input word for spotting\n",
        "input_word = \"ગુજરાતી\"\n",
        "\n",
        "# Tokenize input word and document\n",
        "input_word_tokens = tokenizer.tokenize(input_word)\n",
        "gujarati_tokens = tokenizer.tokenize(gujarati_text)\n",
        "\n",
        "# Calculate embeddings for input word\n",
        "input_word_embeddings = model.base_model.embeddings.word_embeddings(torch.tensor([tokenizer.convert_tokens_to_ids(input_word_tokens)]))\n",
        "\n",
        "# Calculate cosine similarity between input word and each word in the document\n",
        "similarity_scores = []\n",
        "for token in gujarati_tokens:\n",
        "    token_embeddings = model.base_model.embeddings.word_embeddings(torch.tensor([tokenizer.convert_tokens_to_ids([token])]))\n",
        "    similarity = 1 - cosine(input_word_embeddings.squeeze().detach().numpy(), token_embeddings.squeeze().detach().numpy())\n",
        "    similarity_scores.append((token, similarity))\n",
        "\n",
        "# Sort results based on similarity scores\n",
        "similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print top spotted words\n",
        "print(\"Top spotted words similar to '{}' in the document:\".format(input_word))\n",
        "for word, similarity in similarity_scores[:10]:  # Print top 10 similar words\n",
        "    print(\"- {} (Similarity Score: {:.4f})\".format(word, similarity))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using trained model"
      ],
      "metadata": {
        "id": "ub8SCjOZFFDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, BertForMaskedLM\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Load the trained model\n",
        "model_name = \"/content/drive/MyDrive/Word Spotting/model\"\n",
        "model = BertForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Input Gujarati text document\n",
        "gujarati_text = \"સ્વતંત્રતા સંગ્રામની ભાષા અને રાજ્યની ભાષા સાથે બંનેનું કામ કર્યું. ભાષા એ એક સાંસ્કૃતિક મૂળ છે જે માણસને અનેક અનેક અનુભવો આપે છે.ગુજરાતી ભાષા તેમને આત્મતૃપ્તિની અનુભૂતિ આપે છે જે અન્ય ભાષાઓ નહીં આપે. મહાત્મા ગાંધીએ ગુજરાતી ભાષાને ગૌરવ અને આત્માનંદનું પ્રતિષ્ઠાન આપ્યું. ભાષા સામાજિક સંસ્કૃતિનું એક મહત્વપૂર્ણ અંગ છે.\"\n",
        "\n",
        "# Input word for spotting\n",
        "input_word = \"ગુજરાતી\"\n",
        "\n",
        "# Tokenize input word and document\n",
        "input_word_tokens = tokenizer.tokenize(input_word)\n",
        "gujarati_tokens = tokenizer.tokenize(gujarati_text)\n",
        "\n",
        "# Calculate embeddings for input word\n",
        "input_word_embeddings = model.base_model.embeddings.word_embeddings(torch.tensor([tokenizer.convert_tokens_to_ids(input_word_tokens)]))\n",
        "\n",
        "# Calculate cosine similarity between input word and each word in the document\n",
        "similarity_scores = []\n",
        "for token in gujarati_tokens:\n",
        "    token_embeddings = model.base_model.embeddings.word_embeddings(torch.tensor([tokenizer.convert_tokens_to_ids([token])]))\n",
        "    similarity = 1 - cosine(input_word_embeddings.squeeze().detach().numpy(), token_embeddings.squeeze().detach().numpy())\n",
        "    similarity_scores.append((token, similarity))\n",
        "\n",
        "# Sort results based on similarity scores\n",
        "similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print top spotted words\n",
        "print(\"Top spotted words similar to '{}' in the document:\".format(input_word))\n",
        "for word, similarity in similarity_scores[:10]:  # Print top 10 similar words\n",
        "    print(\"- {} (Similarity Score: {:.10f})\".format(word, similarity))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0cxUqfSFErm",
        "outputId": "127d7bc6-96ae-467e-928c-c79d83537276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top spotted words similar to 'ગુજરાતી' in the document:\n",
            "- ગુજરાતી (Similarity Score: 1.0000000000)\n",
            "- ગુજરાતી (Similarity Score: 1.0000000000)\n",
            "- કર્યું (Similarity Score: 0.8517301083)\n",
            "- સાથે (Similarity Score: 0.8457903862)\n",
            "- તેમને (Similarity Score: 0.8452854753)\n",
            "- છે (Similarity Score: 0.8394266367)\n",
            "- છે (Similarity Score: 0.8394266367)\n",
            "- છે (Similarity Score: 0.8394266367)\n",
            "- છે (Similarity Score: 0.8394266367)\n",
            "- ##નું (Similarity Score: 0.8373068571)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}